{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "449c5c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a54d6cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# translation and rotation invariance\n",
    "\n",
    "def align_future(future, center, theta):\n",
    "    xy = future - center\n",
    "    c, s = np.cos(-theta), np.sin(-theta)\n",
    "    x_new = xy[...,0]*c - xy[...,1]*s\n",
    "    y_new = xy[...,0]*s + xy[...,1]*c\n",
    "    return np.stack([x_new, y_new], axis=-1)\n",
    "\n",
    "# converts to a relative coordinate system, so model can focus on the patterns\n",
    "def invariance_transform(past, accel_dt=None):\n",
    "    \"\"\"\n",
    "    Convert a scene to an ego-centric, velocity-aligned frame.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    past : (A, T, 6) float array\n",
    "        [:,:,0:2] = x, y\n",
    "        [:,:,2:4] = vx, vy\n",
    "        [:,:,4]   = heading  (rad)\n",
    "        [:,:,5]   = type_id  (int)\n",
    "    accel_dt : float or None\n",
    "        Sampling period in seconds.  If given, an acceleration\n",
    "        channel is added (Δv / Δt) so output has 8 features.\n",
    "        If None, acceleration is omitted and output has 6 features.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    aligned : (A, T, 7 or 9) float array\n",
    "    center  : (2,)            ego’s last (x,y) in world frame\n",
    "    theta   : float           ego’s last heading (rad)\n",
    "    \"\"\"\n",
    "    A, T, F = past.shape\n",
    "    assert F == 6, f\"expected feat_dim = 6, got {F}\"\n",
    "\n",
    "    pos     = past[..., 0:2]          # (A,T,2)\n",
    "    vel     = past[..., 2:4]          # (A,T,2)\n",
    "    heading = past[..., 4]            # (A,T)\n",
    "    obj_id  = past[..., 5].astype(int)  # keep as float for stacking\n",
    "\n",
    "    # --- translate so ego’s last position is origin ------------------\n",
    "    center = pos[0, -1].copy()        # (2,)\n",
    "    pos_t  = pos - center             # broadcasting (A,T,2) - (2,)\n",
    "\n",
    "    # --- rotate so ego’s last heading is +X --------------------------\n",
    "    theta = heading[0, -1]            # scalar\n",
    "    c, s  = np.cos(-theta), np.sin(-theta)\n",
    "\n",
    "    # Rotate vectors\n",
    "    R = np.array([[c, -s],\n",
    "                  [s,  c]])           # 2×2\n",
    "    pos_r = pos_t @ R.T               # (A,T,2)\n",
    "    vel_r = vel   @ R.T               # (A,T,2)\n",
    "\n",
    "    # --- optional acceleration --------------------------------------\n",
    "    if accel_dt is not None:\n",
    "        inv_dt = 1.0 / accel_dt\n",
    "        acc_r = np.zeros_like(vel_r)\n",
    "        acc_r[:, 1:] = (vel_r[:, 1:] - vel_r[:, :-1]) * inv_dt\n",
    "        features = 9\n",
    "    else:\n",
    "        features = 7\n",
    "\n",
    "    # --- relative heading -------------------------------------------\n",
    "    heading_rel = ((heading - theta + np.pi) % (2*np.pi)) - np.pi  # (A,T)\n",
    "    heading_cos = np.cos(heading_rel)  # (A,T)\n",
    "    heading_sin = np.sin(heading_rel)  # (A,T)\n",
    "    heading_vec = np.stack([heading_cos, heading_sin], axis=-1)  # (A,T,2)\n",
    "\n",
    "    # --- stack output -----------------------------------------------\n",
    "    aligned = np.zeros((A, T, features), dtype=past.dtype)\n",
    "    aligned[..., 0:2] = pos_r\n",
    "    aligned[..., 2:4] = vel_r\n",
    "    if accel_dt is not None:\n",
    "        aligned[..., 4:6] = acc_r\n",
    "        aligned[..., 6:8]   = heading_vec\n",
    "        aligned[..., 8]   = obj_id\n",
    "    else:\n",
    "        aligned[..., 4:6]   = heading_vec\n",
    "        aligned[..., 6]   = obj_id\n",
    "\n",
    "    return aligned, center, theta\n",
    "\n",
    "# batch inverse transform for use outside in prediction, we only care about position inverse rotation and translation\n",
    "def inverse_transform(pred, centers, thetas):\n",
    "    \"\"\"\n",
    "    Bring aligned predictions back to world coordinates.\n",
    "\n",
    "    Args\n",
    "    ----\n",
    "    pred    : (..., T, 2)  aligned positions\n",
    "    centers : (..., 2)     translation(s) subtracted in forward pass\n",
    "    thetas  : (...)        rotation angle(s) (rad), same leading dims as centers\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    world : (..., T, 2)  positions in world frame\n",
    "    \"\"\"\n",
    "    pred    = np.asarray(pred)\n",
    "    centers = np.asarray(centers)\n",
    "    thetas  = np.asarray(thetas)\n",
    "\n",
    "    # Bring everything to shape (..., T, 2)\n",
    "    # Allow leading batch dims of arbitrary rank\n",
    "    # Broadcasting handles scalars automatically.\n",
    "    c = np.cos(thetas)[..., None]      # (..., 1)\n",
    "    s = np.sin(thetas)[..., None]      # (..., 1)\n",
    "\n",
    "    # Rotate back\n",
    "    x, y = pred[..., 0], pred[..., 1]\n",
    "    x_w  = x * c - y * s\n",
    "    y_w  = x * s + y * c\n",
    "    world = np.stack([x_w, y_w], axis=-1)  # (..., T, 2)\n",
    "\n",
    "    # Translate back\n",
    "    world += centers[..., None, :]         # broadcast center over T\n",
    "\n",
    "    return world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "111cd408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ forward + inverse round-trip OK\n"
     ]
    }
   ],
   "source": [
    "## test\n",
    "A, T = 5, 10\n",
    "past = np.random.randn(A, T, 6).astype(np.float32)\n",
    "past[..., 5] = np.random.randint(0, 4, size=(A, T))  # random type IDs\n",
    "\n",
    "aligned, center, theta = invariance_transform(past, accel_dt=0.1)\n",
    "pred_world = inverse_transform(aligned[0, :, :2], center, theta)  # ego track back to world\n",
    "\n",
    "assert np.allclose(pred_world, past[0, :, :2], atol=1e-5)\n",
    "print(\"✓ forward + inverse round-trip OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c723ae78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    l = len(batch[0])\n",
    "    if l == 3:\n",
    "        # train: (past,mask,future)\n",
    "        pasts, masks, futures = zip(*batch)\n",
    "        return (\n",
    "            torch.stack(pasts),\n",
    "            torch.stack(masks),\n",
    "            torch.stack(futures),\n",
    "        )\n",
    "    elif l == 4:\n",
    "        # test: (past,mask,center,theta)\n",
    "        pasts, masks, centers, thetas = zip(*batch)\n",
    "        return (\n",
    "            torch.stack(pasts),\n",
    "            torch.stack(masks),\n",
    "            torch.stack(centers),      # shape (B,2)\n",
    "            torch.stack(thetas),       # shape (B,)\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unrecognized sample of length {l}\")\n",
    "    \n",
    "\n",
    "class TrajectoryDataset(Dataset):\n",
    "    def __init__(self, input_path=None, data=None, T_past=50, T_future=60, is_test=False):\n",
    "        if data is not None:\n",
    "            self.data = data\n",
    "        else:\n",
    "            npz = np.load(input_path)\n",
    "            self.data = npz['data']\n",
    "        self.T_past = T_past\n",
    "        self.T_future = T_future\n",
    "        self.is_test = is_test\n",
    "\n",
    "        # Calculate normalization statistics from the past data\n",
    "        self.calculate_normalization_stats()\n",
    "\n",
    "        \n",
    "    def calculate_normalization_stats(self):\n",
    "        \"\"\"Calculate mean and std for efficient normalization\"\"\"\n",
    "        #align past data\n",
    "        all_pos = []\n",
    "        all_vel = []\n",
    "        for scene in self.data:\n",
    "            past = scene[:, :self.T_past, :].copy()\n",
    "            past_aligned, _, _ = invariance_transform(past)\n",
    "\n",
    "            # collect positions & velocities across all agents & all time-steps\n",
    "            all_pos.append(past_aligned[..., :2].reshape(-1, 2))\n",
    "            all_vel.append(past_aligned[..., 2:4].reshape(-1, 2))\n",
    "\n",
    "        all_pos = np.concatenate(all_pos, axis=0)\n",
    "        all_vel = np.concatenate(all_vel, axis=0)\n",
    "\n",
    "        # # now compute statistics on the aligned data\n",
    "        # self.pos_mean = all_pos.mean(axis=0)\n",
    "        # self.pos_std  = np.maximum(all_pos.std(axis=0), 1e-6)\n",
    "        # self.vel_mean = all_vel.mean(axis=0)\n",
    "        # self.vel_std  = np.maximum(all_vel.std(axis=0), 1e-6)\n",
    "\n",
    "        # Only consider non-zero values for position and velocity\n",
    "        #positions = self.data[..., :2]  # x, y positions\n",
    "        mask = np.abs(all_pos).sum(axis=-1) > 0\n",
    "        \n",
    "        if mask.sum() > 0:\n",
    "            valid_positions = all_pos[mask]\n",
    "            self.pos_mean = valid_positions.mean(axis=0)\n",
    "            self.pos_std = valid_positions.std(axis=0)\n",
    "            \n",
    "            # Ensure std is not zero to avoid division by zero\n",
    "            self.pos_std = np.maximum(self.pos_std, 1e-6)\n",
    "        else:\n",
    "            self.pos_mean = np.zeros(2)\n",
    "            self.pos_std = np.ones(2)\n",
    "            \n",
    "        # Same for velocities\n",
    "        #velocities = self.data[..., 2:4]  # vx, vy velocities\n",
    "        mask = np.abs(all_vel).sum(axis=-1) > 0\n",
    "        \n",
    "        if mask.sum() > 0:\n",
    "            valid_velocities = all_vel[mask]\n",
    "            self.vel_mean = valid_velocities.mean(axis=0)\n",
    "            self.vel_std = valid_velocities.std(axis=0)\n",
    "            self.vel_std = np.maximum(self.vel_std, 1e-6)\n",
    "        else:\n",
    "            self.vel_mean = np.zeros(2)\n",
    "            self.vel_std = np.ones(2)\n",
    "            \n",
    "    def normalize_features(self, features):\n",
    "        \"\"\"Normalize features efficiently\"\"\"\n",
    "        normalized = features.copy()\n",
    "        # Normalize positions (x, y)\n",
    "        normalized[..., 0:2] = (features[..., 0:2] - self.pos_mean) / self.pos_std\n",
    "        # Normalize velocities (vx, vy)\n",
    "        normalized[..., 2:4] = (features[..., 2:4] - self.vel_mean) / self.vel_std\n",
    "        # Normalize acceleration (ax, ay) # it's not present RN\n",
    "        # if features.shape[-1] >= 6:  # If acceleration is present\n",
    "        #     normalized[..., 4:6] = (features[..., 4:6] - self.vel_mean) / self.vel_std\n",
    "        return normalized\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        scene = self.data[idx]  # (num_agents, T, features) per scene calculations\n",
    "        \n",
    "        # Extract past trajectory\n",
    "        past = scene[:, :self.T_past, :].copy()  # (num_agents, T_past, features)\n",
    "\n",
    "        \n",
    "        #TODO not only is overwriting heading and object features, but also its calculating acceleration based on velocity we are about to transform\n",
    "\n",
    "        # # If acceleration is not already in the data, calculate it\n",
    "        # if past.shape[-1] < 6:\n",
    "        #     # Original features are likely x, y, vx, vy\n",
    "        #     # Calculate acceleration from velocity if not already present\n",
    "        #     num_agents, T, _ = past.shape\n",
    "            \n",
    "        #     # Create a new array with extra space for acceleration\n",
    "        #     past_with_accel = np.zeros((num_agents, T, 6))\n",
    "            \n",
    "        #     # Copy existing features\n",
    "        #     past_with_accel[:, :, :past.shape[-1]] = past\n",
    "            \n",
    "        #     # If velocity exists, calculate acceleration as the derivative of velocity\n",
    "        #     if past.shape[-1] >= 4:  # If we have velocity\n",
    "        #         # Calculate acceleration (dvx, dvy) by differentiating velocity\n",
    "        #         accel = np.zeros((num_agents, T, 2))\n",
    "        #         accel[:, 1:, :] = past[:, 1:, 2:4] - past[:, :-1, 2:4]  # Simple finite difference\n",
    "        #         past_with_accel[:, :, 4:6] = accel\n",
    "            \n",
    "        #     past = past_with_accel\n",
    "\n",
    "        # Apply translation + rotation invariance per scene \n",
    "        # (shifts ego → origin & rotates so ego’s heading is +x)\n",
    "        # note acceleration is included in the past data this time\n",
    "        past_aligned, center, theta = invariance_transform(past)\n",
    "        \n",
    "        # Normalize features\n",
    "        past_aligned_normalized = self.normalize_features(past_aligned)\n",
    "        \n",
    "        # Create mask for valid agents (based on position)\n",
    "        mask = np.sum(np.abs(past[:, :, :2]), axis=(1, 2)) > 0\n",
    "        \n",
    "        # For training data, also extract and normalize future trajectory of ego vehicle\n",
    "        if not self.is_test and scene.shape[1] >= self.T_past + self.T_future:\n",
    "            future_raw = scene[0, self.T_past:self.T_past+self.T_future, :2]  # Ego vehicle future (x, y)\n",
    "            # align future ego to the same reference frame, then normalize\n",
    "            future_aligned = align_future(future_raw, center, theta)\n",
    "            future_aligned_normalized = (future_aligned - self.pos_mean) / self.pos_std\n",
    "            \n",
    "            return (\n",
    "                torch.tensor(past_aligned_normalized, dtype=torch.float32),\n",
    "                torch.tensor(mask, dtype=torch.bool),\n",
    "                torch.tensor(future_aligned_normalized, dtype=torch.float32)\n",
    "            )\n",
    "        \n",
    "        # For test data, only return aligned and normalized past\n",
    "        return (\n",
    "            torch.tensor(past_aligned_normalized, dtype=torch.float32),\n",
    "            torch.tensor(mask, dtype=torch.bool),\n",
    "            torch.tensor(center, dtype=torch.float32),\n",
    "            torch.tensor(theta, dtype=torch.float32)\n",
    "        )\n",
    "    \n",
    "    def denormalize_prediction(self, prediction):\n",
    "        \"\"\"Convert normalized predictions back to original scale\"\"\"\n",
    "        return prediction * self.pos_std + self.pos_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "683bc19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:x.size(0), :]\n",
    "\n",
    "class AgentTypeEmbedding(nn.Module):\n",
    "    def __init__(self, num_types=10, d_model=128):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(num_types, d_model)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Use default type if type information is not available\n",
    "        if x.shape[-1] == 6:  # If we only have x, y, vx, vy, ax, ay, heading, object type\n",
    "            # Create default type tensor (all zeros)\n",
    "            obj_type = torch.zeros(x.shape[:-1], dtype=torch.long, device=x.device)\n",
    "        else:\n",
    "            obj_type = x[..., -1].long()\n",
    "        return self.embedding(obj_type)\n",
    "\n",
    "class ImprovedTrajectoryTransformer(nn.Module):\n",
    "    def __init__(self, feature_dim=6, d_model=256, nhead=8,\n",
    "                 num_layers=4, dim_feedforward=512, \n",
    "                 T_past=50, T_future=60, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.T_past = T_past\n",
    "        self.T_future = T_future\n",
    "        \n",
    "        # Feature embedding for positions, velocities, accelerations\n",
    "        self.feature_embed = nn.Linear(feature_dim, d_model)\n",
    "        \n",
    "        # Object type embedding\n",
    "        self.type_embedding = AgentTypeEmbedding(num_types=10, d_model=d_model)\n",
    "        \n",
    "        # Positional encoding for timesteps\n",
    "        self.pos_encoding = PositionalEncoding(d_model)\n",
    "        \n",
    "        # Layer normalization\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        \n",
    "        # Transformer encoder for temporal relations\n",
    "        temporal_encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, \n",
    "            nhead=nhead, \n",
    "            dim_feedforward=dim_feedforward, \n",
    "            dropout=dropout,\n",
    "            batch_first=False\n",
    "        )\n",
    "        self.temporal_encoder = nn.TransformerEncoder(\n",
    "            temporal_encoder_layer, \n",
    "            num_layers=num_layers//2\n",
    "        )\n",
    "        \n",
    "        # Transformer encoder for social relations\n",
    "        social_encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, \n",
    "            nhead=nhead, \n",
    "            dim_feedforward=dim_feedforward, \n",
    "            dropout=dropout,\n",
    "            batch_first=False\n",
    "        )\n",
    "        self.social_encoder = nn.TransformerEncoder(\n",
    "            social_encoder_layer, \n",
    "            num_layers=num_layers//2\n",
    "        )\n",
    "        \n",
    "        # Output MLP\n",
    "        self.prediction_head = nn.Sequential(\n",
    "            nn.Linear(d_model, dim_feedforward),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(dim_feedforward, dim_feedforward // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(dim_feedforward // 2, 2 * T_future)\n",
    "        )\n",
    "        \n",
    "    def forward(self, past, agent_mask):\n",
    "        B, N, T, F = past.shape  # Batch, Num_agents, Time, Features\n",
    "\n",
    "        assert F >= 7, f\"Expected at least 7 features, got {F}\"\n",
    "        \n",
    "        # Embed all features directly\n",
    "        features_flat = past.reshape(B * N * T, F)\n",
    "        feature_embedding = self.feature_embed(features_flat) #project to higher space\n",
    "        feature_embedding = feature_embedding.reshape(B, N, T, self.d_model)\n",
    "        \n",
    "        # Get object type embedding\n",
    "        type_embedding = self.type_embedding(past)  # B, N, T, d_model\n",
    "        \n",
    "        # Combine embeddings\n",
    "        combined_embedding = feature_embedding + type_embedding\n",
    "        \n",
    "        # Reshape for temporal transformer: (T, B*N, d_model)\n",
    "        temporal_input = combined_embedding.permute(2, 0, 1, 3).reshape(T, B*N, self.d_model)\n",
    "        \n",
    "        # Add positional encoding\n",
    "        temporal_input = self.pos_encoding(temporal_input)\n",
    "        \n",
    "        # Apply temporal transformer\n",
    "        temporal_output = self.temporal_encoder(temporal_input)\n",
    "        \n",
    "        # Get the last temporal state for each agent\n",
    "        agent_features = temporal_output[-1].reshape(B, N, self.d_model)  # B, N, d_model\n",
    "        \n",
    "        # Make sure there's at least one valid agent per batch\n",
    "        if (~agent_mask).all(dim=1).any():\n",
    "            fallback_mask = agent_mask.clone()\n",
    "            fallback_mask[:, 0] = True  # At least use ego vehicle\n",
    "            agent_mask = torch.where(agent_mask.sum(dim=1, keepdim=True) == 0, fallback_mask, agent_mask)\n",
    "        \n",
    "        # Prepare for social transformer: (N, B, d_model)\n",
    "        social_input = agent_features.permute(1, 0, 2) #want agent features back in the first dim, not time\n",
    "        \n",
    "        # Apply social transformer with masking\n",
    "        social_output = self.social_encoder(social_input, src_key_padding_mask=~agent_mask)\n",
    "        \n",
    "        # Extract ego vehicle embedding\n",
    "        ego_embedding = social_output[0]  # B, d_model\n",
    "        \n",
    "        # Apply prediction head\n",
    "        trajectory_flat = self.prediction_head(ego_embedding)  # B, 2*T_future\n",
    "        \n",
    "        # Reshape to (Batch, Time, XY)\n",
    "        predictions = trajectory_flat.reshape(B, self.T_future, 2)\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "69bf5e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, optimizer, device, clip_grad=.3):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        past, mask, future = [x.to(device) for x in batch]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        pred = model(past, mask)\n",
    "        \n",
    "        loss = criterion(pred, future)\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=clip_grad)\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * past.size(0)\n",
    "    \n",
    "    return total_loss / len(dataloader.dataset)\n",
    "\n",
    "def evaluate(model, val_loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            past, mask, future = [x.to(device) for x in batch]\n",
    "            pred = model(past, mask)\n",
    "            loss = criterion(pred, future)\n",
    "            total_loss += loss.item() * past.size(0)\n",
    "    \n",
    "    return total_loss / len(val_loader.dataset)\n",
    "\n",
    "@torch.inference_mode() \n",
    "def  predict(model, test_loader, test_dataset, device):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    all_preds = []\n",
    "    \n",
    "    for past, mask, centers, thetas in test_loader:\n",
    "        past = past.to(device, non_blocking=True).float()\n",
    "        mask = mask.to(device, non_blocking=True)\n",
    "        \n",
    "        #predict in normalized aligned space\n",
    "        pred_norm = model(past, mask).cpu().numpy()\n",
    "\n",
    "        #undo normalization (still aligned)\n",
    "        pred_aligned = test_dataset.denormalize_prediction(pred_norm)\n",
    "\n",
    "        #undo relative alignment -> output world coords\n",
    "        pred_world = inverse_transform(\n",
    "            pred_aligned, \n",
    "            centers.numpy(), \n",
    "            thetas.numpy()\n",
    "        )\n",
    "        \n",
    "        all_preds.append(pred_world)\n",
    "    \n",
    "    return np.concatenate(all_preds, axis=0)\n",
    "\n",
    "def get_latest_checkpoint(folder):\n",
    "    files = glob.glob(os.path.join(folder, \"ckpt_epoch_*.pt\"))\n",
    "    if not files:\n",
    "        return None\n",
    "    return max(files, key=lambda f: int(re.findall(r\"ckpt_epoch_(\\d+)\", f)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "69aff322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "train_input = 'data/train.npz'\n",
    "test_input = 'data/test_input.npz'\n",
    "output_csv = 'predictions.csv'\n",
    "checkpoint_path = 'best_model.pt'\n",
    "checkpoints_dir = 'checkpoints'\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 64\n",
    "lr = 1e-4\n",
    "weight_decay = 1e-5\n",
    "epochs = 1000\n",
    "patience = 15  # Early stopping patience\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps' if torch.mps.is_available() else 'cpu')\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4421e7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load data\n",
    "full_data = np.load(train_input)['data']\n",
    "\n",
    "# Split into train and validation (7:3)\n",
    "num_samples = len(full_data)\n",
    "num_train = int(0.8 * num_samples)\n",
    "perm = np.random.permutation(num_samples)\n",
    "train_idx = perm[:num_train]\n",
    "val_idx = perm[num_train:]\n",
    "\n",
    "train_data = full_data[train_idx]\n",
    "val_data = full_data[val_idx]\n",
    "\n",
    "# Create datasets with normalization\n",
    "train_ds = TrajectoryDataset(data=train_data)\n",
    "val_ds = TrajectoryDataset(data=val_data)\n",
    "\n",
    "# Create test dataset using the same normalization stats as training\n",
    "test_ds = TrajectoryDataset(input_path=test_input, is_test=True)\n",
    "# Copy normalization stats from train_ds\n",
    "test_ds.pos_mean = train_ds.pos_mean\n",
    "test_ds.pos_std = train_ds.pos_std\n",
    "test_ds.vel_mean = train_ds.vel_mean\n",
    "test_ds.vel_std = train_ds.vel_std\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a680bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "45724902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First sample: tensor([[[[-1.4462e-02, -1.6054e-04,  1.3743e+00,  ...,  9.9999e-01,\n",
      "           -5.2109e-03,  0.0000e+00],\n",
      "          [-1.4305e-02, -1.6142e-04,  1.3743e+00,  ...,  9.9999e-01,\n",
      "           -5.2162e-03,  0.0000e+00],\n",
      "          [-1.4113e-02, -1.6244e-04,  1.3791e+00,  ...,  9.9999e-01,\n",
      "           -5.2020e-03,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 5.8963e-04, -1.3641e-04,  1.9003e+00,  ...,  1.0000e+00,\n",
      "            6.1093e-04,  0.0000e+00],\n",
      "          [ 9.6926e-04, -1.3563e-04,  1.9484e+00,  ...,  1.0000e+00,\n",
      "            3.1902e-04,  0.0000e+00],\n",
      "          [ 1.3501e-03, -1.3493e-04,  1.9449e+00,  ...,  1.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 1.2238e-02,  2.4020e-03, -1.5797e+00,  ..., -9.9999e-01,\n",
      "            3.4182e-03,  4.0000e+00],\n",
      "          [ 1.2084e-02,  2.3963e-03, -1.5661e+00,  ..., -1.0000e+00,\n",
      "            2.6245e-03,  4.0000e+00],\n",
      "          [ 1.1900e-02,  2.3905e-03, -1.5532e+00,  ..., -1.0000e+00,\n",
      "            1.8207e-03,  4.0000e+00],\n",
      "          ...,\n",
      "          [ 1.8023e-03,  2.3619e-03, -1.2021e+00,  ..., -9.9999e-01,\n",
      "           -4.1680e-03,  4.0000e+00],\n",
      "          [ 1.5057e-03,  2.3610e-03, -1.2016e+00,  ..., -9.9999e-01,\n",
      "           -3.3828e-03,  4.0000e+00],\n",
      "          [ 1.2050e-03,  2.3596e-03, -1.1896e+00,  ..., -1.0000e+00,\n",
      "           -2.9798e-03,  4.0000e+00]],\n",
      "\n",
      "         [[-7.9358e-03, -1.4883e-03,  1.4006e+00,  ...,  9.9998e-01,\n",
      "            6.0541e-03,  4.0000e+00],\n",
      "          [-7.7741e-03, -1.4880e-03,  1.4188e+00,  ...,  9.9998e-01,\n",
      "            6.3484e-03,  4.0000e+00],\n",
      "          [-7.5775e-03, -1.4874e-03,  1.4367e+00,  ...,  9.9998e-01,\n",
      "            6.6648e-03,  4.0000e+00],\n",
      "          ...,\n",
      "          [ 6.9176e-03, -1.4633e-03,  1.5912e+00,  ...,  9.9999e-01,\n",
      "            4.2902e-03,  4.0000e+00],\n",
      "          [ 7.2260e-03, -1.4591e-03,  1.5860e+00,  ...,  9.9999e-01,\n",
      "            3.7388e-03,  4.0000e+00],\n",
      "          [ 7.5358e-03, -1.4546e-03,  1.5804e+00,  ...,  1.0000e+00,\n",
      "            3.0573e-03,  4.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.3925e+00,  7.3168e-01, -1.2602e-01,  ..., -9.9943e-01,\n",
      "            3.3734e-02,  0.0000e+00],\n",
      "          [ 2.3925e+00,  7.3168e-01, -1.2602e-01,  ..., -9.9943e-01,\n",
      "            3.3734e-02,  0.0000e+00],\n",
      "          [ 2.3925e+00,  7.3168e-01, -1.2602e-01,  ..., -9.9943e-01,\n",
      "            3.3734e-02,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 2.3925e+00,  7.3168e-01, -1.2602e-01,  ..., -9.9943e-01,\n",
      "            3.3734e-02,  0.0000e+00],\n",
      "          [ 2.3925e+00,  7.3168e-01, -1.2602e-01,  ..., -9.9943e-01,\n",
      "            3.3734e-02,  0.0000e+00],\n",
      "          [ 2.3925e+00,  7.3168e-01, -1.2602e-01,  ..., -9.9943e-01,\n",
      "            3.3734e-02,  0.0000e+00]],\n",
      "\n",
      "         [[ 2.3925e+00,  7.3168e-01, -1.2602e-01,  ..., -9.9943e-01,\n",
      "            3.3734e-02,  0.0000e+00],\n",
      "          [ 2.3925e+00,  7.3168e-01, -1.2602e-01,  ..., -9.9943e-01,\n",
      "            3.3734e-02,  0.0000e+00],\n",
      "          [ 2.3925e+00,  7.3168e-01, -1.2602e-01,  ..., -9.9943e-01,\n",
      "            3.3734e-02,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 2.3925e+00,  7.3168e-01, -1.2602e-01,  ..., -9.9943e-01,\n",
      "            3.3734e-02,  0.0000e+00],\n",
      "          [ 2.3925e+00,  7.3168e-01, -1.2602e-01,  ..., -9.9943e-01,\n",
      "            3.3734e-02,  0.0000e+00],\n",
      "          [ 2.3925e+00,  7.3168e-01, -1.2602e-01,  ..., -9.9943e-01,\n",
      "            3.3734e-02,  0.0000e+00]],\n",
      "\n",
      "         [[ 2.3925e+00,  7.3168e-01, -1.2602e-01,  ..., -9.9943e-01,\n",
      "            3.3734e-02,  0.0000e+00],\n",
      "          [ 2.3925e+00,  7.3168e-01, -1.2602e-01,  ..., -9.9943e-01,\n",
      "            3.3734e-02,  0.0000e+00],\n",
      "          [ 2.3925e+00,  7.3168e-01, -1.2602e-01,  ..., -9.9943e-01,\n",
      "            3.3734e-02,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 2.3925e+00,  7.3168e-01, -1.2602e-01,  ..., -9.9943e-01,\n",
      "            3.3734e-02,  0.0000e+00],\n",
      "          [ 2.3925e+00,  7.3168e-01, -1.2602e-01,  ..., -9.9943e-01,\n",
      "            3.3734e-02,  0.0000e+00],\n",
      "          [ 2.3925e+00,  7.3168e-01, -1.2602e-01,  ..., -9.9943e-01,\n",
      "            3.3734e-02,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-1.9385e-02, -9.6940e-05,  1.0598e+00,  ...,  9.9999e-01,\n",
      "            4.8334e-03,  0.0000e+00],\n",
      "          [-1.9169e-02, -9.6604e-05,  1.0598e+00,  ...,  9.9999e-01,\n",
      "            5.0124e-03,  0.0000e+00],\n",
      "          [-1.8902e-02, -9.6221e-05,  2.2120e+00,  ...,  9.9999e-01,\n",
      "            5.1716e-03,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 4.8818e-04, -1.3228e-04,  2.2168e+00,  ...,  1.0000e+00,\n",
      "            8.0003e-04,  0.0000e+00],\n",
      "          [ 9.1900e-04, -1.3350e-04,  2.2016e+00,  ...,  1.0000e+00,\n",
      "            4.0807e-04,  0.0000e+00],\n",
      "          [ 1.3501e-03, -1.3493e-04,  2.2031e+00,  ...,  1.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 1.4664e-02,  2.9361e-03, -1.2848e-01,  ..., -1.0000e+00,\n",
      "           -1.1246e-03,  0.0000e+00],\n",
      "          [ 1.4666e-02,  2.9338e-03, -1.2905e-01,  ..., -1.0000e+00,\n",
      "           -9.8023e-04,  0.0000e+00],\n",
      "          [ 1.4667e-02,  2.9309e-03, -1.2965e-01,  ..., -1.0000e+00,\n",
      "           -7.7587e-04,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 1.4810e-02,  2.7426e-03, -1.2602e-01,  ..., -1.0000e+00,\n",
      "           -2.6270e-03,  0.0000e+00],\n",
      "          [ 1.4809e-02,  2.7396e-03, -1.2602e-01,  ..., -1.0000e+00,\n",
      "           -2.9000e-03,  0.0000e+00],\n",
      "          [ 1.4809e-02,  2.7369e-03, -1.2602e-01,  ..., -9.9999e-01,\n",
      "           -3.1556e-03,  0.0000e+00]],\n",
      "\n",
      "         [[ 4.6028e-04,  2.7118e-03, -1.2602e-01,  ..., -1.0000e+00,\n",
      "            3.3810e-04,  0.0000e+00],\n",
      "          [ 4.6028e-04,  2.7114e-03, -1.2602e-01,  ..., -1.0000e+00,\n",
      "            2.6995e-04,  0.0000e+00],\n",
      "          [ 4.6001e-04,  2.7106e-03, -1.2602e-01,  ..., -1.0000e+00,\n",
      "            1.7104e-04,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 4.7970e-04,  2.6685e-03, -1.2602e-01,  ..., -1.0000e+00,\n",
      "           -9.6378e-04,  0.0000e+00],\n",
      "          [ 4.8471e-04,  2.6687e-03, -1.2602e-01,  ..., -1.0000e+00,\n",
      "           -9.8410e-04,  0.0000e+00],\n",
      "          [ 4.9024e-04,  2.6690e-03, -1.2602e-01,  ..., -1.0000e+00,\n",
      "           -1.1097e-03,  0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.0272e-01,  1.0006e+00, -1.2602e-01,  ..., -6.1076e-01,\n",
      "            7.9181e-01,  0.0000e+00],\n",
      "          [ 2.0272e-01,  1.0006e+00, -1.2602e-01,  ..., -6.1076e-01,\n",
      "            7.9181e-01,  0.0000e+00],\n",
      "          [ 2.0272e-01,  1.0006e+00, -1.2602e-01,  ..., -6.1076e-01,\n",
      "            7.9181e-01,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 2.0272e-01,  1.0006e+00, -1.2602e-01,  ..., -6.1076e-01,\n",
      "            7.9181e-01,  0.0000e+00],\n",
      "          [ 2.0272e-01,  1.0006e+00, -1.2602e-01,  ..., -6.1076e-01,\n",
      "            7.9181e-01,  0.0000e+00],\n",
      "          [ 2.0272e-01,  1.0006e+00, -1.2602e-01,  ..., -6.1076e-01,\n",
      "            7.9181e-01,  0.0000e+00]],\n",
      "\n",
      "         [[ 2.0272e-01,  1.0006e+00, -1.2602e-01,  ..., -6.1076e-01,\n",
      "            7.9181e-01,  0.0000e+00],\n",
      "          [ 2.0272e-01,  1.0006e+00, -1.2602e-01,  ..., -6.1076e-01,\n",
      "            7.9181e-01,  0.0000e+00],\n",
      "          [ 2.0272e-01,  1.0006e+00, -1.2602e-01,  ..., -6.1076e-01,\n",
      "            7.9181e-01,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 2.0272e-01,  1.0006e+00, -1.2602e-01,  ..., -6.1076e-01,\n",
      "            7.9181e-01,  0.0000e+00],\n",
      "          [ 2.0272e-01,  1.0006e+00, -1.2602e-01,  ..., -6.1076e-01,\n",
      "            7.9181e-01,  0.0000e+00],\n",
      "          [ 2.0272e-01,  1.0006e+00, -1.2602e-01,  ..., -6.1076e-01,\n",
      "            7.9181e-01,  0.0000e+00]],\n",
      "\n",
      "         [[ 2.0272e-01,  1.0006e+00, -1.2602e-01,  ..., -6.1076e-01,\n",
      "            7.9181e-01,  0.0000e+00],\n",
      "          [ 2.0272e-01,  1.0006e+00, -1.2602e-01,  ..., -6.1076e-01,\n",
      "            7.9181e-01,  0.0000e+00],\n",
      "          [ 2.0272e-01,  1.0006e+00, -1.2602e-01,  ..., -6.1076e-01,\n",
      "            7.9181e-01,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 2.0272e-01,  1.0006e+00, -1.2602e-01,  ..., -6.1076e-01,\n",
      "            7.9181e-01,  0.0000e+00],\n",
      "          [ 2.0272e-01,  1.0006e+00, -1.2602e-01,  ..., -6.1076e-01,\n",
      "            7.9181e-01,  0.0000e+00],\n",
      "          [ 2.0272e-01,  1.0006e+00, -1.2602e-01,  ..., -6.1076e-01,\n",
      "            7.9181e-01,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-1.7009e-02, -4.4287e-04,  8.5240e-01,  ...,  9.9995e-01,\n",
      "            1.0158e-02,  0.0000e+00],\n",
      "          [-1.6830e-02, -4.4204e-04,  8.5240e-01,  ...,  9.9996e-01,\n",
      "            9.4149e-03,  0.0000e+00],\n",
      "          [-1.6609e-02, -4.4115e-04,  1.8123e+00,  ...,  9.9996e-01,\n",
      "            8.5363e-03,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 5.2187e-04, -1.3022e-04,  2.1120e+00,  ...,  1.0000e+00,\n",
      "           -1.8029e-03,  0.0000e+00],\n",
      "          [ 9.3525e-04, -1.3277e-04,  2.1267e+00,  ...,  1.0000e+00,\n",
      "           -9.6434e-04,  0.0000e+00],\n",
      "          [ 1.3501e-03, -1.3493e-04,  2.1291e+00,  ...,  1.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 3.7396e-03,  2.3584e-03, -1.2602e-01,  ..., -9.9998e-01,\n",
      "           -6.4097e-03,  0.0000e+00],\n",
      "          [ 3.7380e-03,  2.3582e-03, -1.2602e-01,  ..., -9.9998e-01,\n",
      "           -6.4812e-03,  0.0000e+00],\n",
      "          [ 3.7371e-03,  2.3568e-03, -1.2602e-01,  ..., -9.9998e-01,\n",
      "           -6.6683e-03,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 3.6516e-03,  2.3064e-03, -1.2602e-01,  ..., -9.9997e-01,\n",
      "           -7.3710e-03,  0.0000e+00],\n",
      "          [ 3.6542e-03,  2.3070e-03, -1.2602e-01,  ..., -9.9997e-01,\n",
      "           -7.0946e-03,  0.0000e+00],\n",
      "          [ 3.6567e-03,  2.3074e-03, -1.2602e-01,  ..., -9.9998e-01,\n",
      "           -6.7953e-03,  0.0000e+00]],\n",
      "\n",
      "         [[ 1.9065e-03, -1.2593e-03, -2.5253e-01,  ...,  9.9987e-01,\n",
      "            1.6304e-02,  0.0000e+00],\n",
      "          [ 1.9663e-03, -1.2896e-03, -2.5253e-01,  ...,  9.9986e-01,\n",
      "            1.6817e-02,  0.0000e+00],\n",
      "          [ 2.0288e-03, -1.3197e-03, -1.9870e-01,  ...,  9.9984e-01,\n",
      "            1.7706e-02,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 2.2234e-03, -1.4095e-03, -1.2602e-01,  ...,  9.9936e-01,\n",
      "            3.5639e-02,  0.0000e+00],\n",
      "          [ 2.2241e-03, -1.4104e-03, -1.2602e-01,  ...,  9.9935e-01,\n",
      "            3.6132e-02,  0.0000e+00],\n",
      "          [ 2.2247e-03, -1.4112e-03, -1.2602e-01,  ...,  9.9933e-01,\n",
      "            3.6699e-02,  0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.0688e-02, -1.7776e-03, -4.8532e-02,  ...,  9.9993e-01,\n",
      "           -1.1639e-02,  0.0000e+00],\n",
      "          [-2.0700e-02, -1.7769e-03, -3.9858e-02,  ...,  9.9993e-01,\n",
      "           -1.2070e-02,  0.0000e+00],\n",
      "          [-2.0709e-02, -1.7763e-03, -4.0131e-02,  ...,  9.9992e-01,\n",
      "           -1.2828e-02,  0.0000e+00],\n",
      "          ...,\n",
      "          [-8.5828e-01,  2.1699e+00, -1.2602e-01,  ...,  1.0831e-01,\n",
      "           -9.9412e-01,  0.0000e+00],\n",
      "          [-8.5828e-01,  2.1699e+00, -1.2602e-01,  ...,  1.0831e-01,\n",
      "           -9.9412e-01,  0.0000e+00],\n",
      "          [-8.5828e-01,  2.1699e+00, -1.2602e-01,  ...,  1.0831e-01,\n",
      "           -9.9412e-01,  0.0000e+00]],\n",
      "\n",
      "         [[-8.5828e-01,  2.1699e+00, -1.2602e-01,  ...,  1.0831e-01,\n",
      "           -9.9412e-01,  0.0000e+00],\n",
      "          [-8.5828e-01,  2.1699e+00, -1.2602e-01,  ...,  1.0831e-01,\n",
      "           -9.9412e-01,  0.0000e+00],\n",
      "          [-8.5828e-01,  2.1699e+00, -1.2602e-01,  ...,  1.0831e-01,\n",
      "           -9.9412e-01,  0.0000e+00],\n",
      "          ...,\n",
      "          [-8.5828e-01,  2.1699e+00, -1.2602e-01,  ...,  1.0831e-01,\n",
      "           -9.9412e-01,  0.0000e+00],\n",
      "          [-8.5828e-01,  2.1699e+00, -1.2602e-01,  ...,  1.0831e-01,\n",
      "           -9.9412e-01,  0.0000e+00],\n",
      "          [-8.5828e-01,  2.1699e+00, -1.2602e-01,  ...,  1.0831e-01,\n",
      "           -9.9412e-01,  0.0000e+00]],\n",
      "\n",
      "         [[-8.5828e-01,  2.1699e+00, -1.2602e-01,  ...,  1.0831e-01,\n",
      "           -9.9412e-01,  0.0000e+00],\n",
      "          [-8.5828e-01,  2.1699e+00, -1.2602e-01,  ...,  1.0831e-01,\n",
      "           -9.9412e-01,  0.0000e+00],\n",
      "          [-8.5828e-01,  2.1699e+00, -1.2602e-01,  ...,  1.0831e-01,\n",
      "           -9.9412e-01,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 1.1635e-02, -5.4650e-03, -1.2602e-01,  ...,  1.0000e+00,\n",
      "           -2.3864e-03,  5.0000e+00],\n",
      "          [ 1.1634e-02, -5.5557e-03, -1.2602e-01,  ...,  1.0000e+00,\n",
      "           -2.3874e-03,  5.0000e+00],\n",
      "          [ 1.1633e-02, -5.6568e-03, -1.2602e-01,  ...,  1.0000e+00,\n",
      "           -2.3863e-03,  5.0000e+00]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-2.3949e-03, -2.4324e-04,  1.8422e-01,  ...,  9.9973e-01,\n",
      "            2.3349e-02,  0.0000e+00],\n",
      "          [-2.3365e-03, -2.4212e-04,  1.8422e-01,  ...,  9.9970e-01,\n",
      "            2.4514e-02,  0.0000e+00],\n",
      "          [-2.2636e-03, -2.4051e-04,  4.9599e-01,  ...,  9.9966e-01,\n",
      "            2.5884e-02,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 1.3394e-03, -1.3297e-04, -7.5517e-02,  ...,  1.0000e+00,\n",
      "           -2.3514e-03,  0.0000e+00],\n",
      "          [ 1.3455e-03, -1.3391e-04, -8.4348e-02,  ...,  1.0000e+00,\n",
      "           -1.0443e-03,  0.0000e+00],\n",
      "          [ 1.3501e-03, -1.3493e-04, -9.5971e-02,  ...,  1.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 8.1177e-03,  2.1320e-02, -1.2602e-01,  ..., -5.2985e-02,\n",
      "            9.9860e-01,  0.0000e+00],\n",
      "          [ 8.1132e-03,  2.1400e-02, -1.2602e-01,  ..., -5.3656e-02,\n",
      "            9.9856e-01,  0.0000e+00],\n",
      "          [ 8.1085e-03,  2.1480e-02, -1.2602e-01,  ..., -5.4424e-02,\n",
      "            9.9852e-01,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 8.0667e-03,  2.1740e-02, -1.2602e-01,  ..., -8.6531e-02,\n",
      "            9.9625e-01,  0.0000e+00],\n",
      "          [ 8.0652e-03,  2.1741e-02, -1.2602e-01,  ..., -8.5664e-02,\n",
      "            9.9632e-01,  0.0000e+00],\n",
      "          [ 8.0639e-03,  2.1740e-02, -1.2602e-01,  ..., -8.4422e-02,\n",
      "            9.9643e-01,  0.0000e+00]],\n",
      "\n",
      "         [[-8.3279e-03, -3.6588e-03,  2.4801e+00,  ...,  9.9996e-01,\n",
      "            8.5919e-03,  0.0000e+00],\n",
      "          [-8.1159e-03, -3.6550e-03,  2.4639e+00,  ...,  9.9995e-01,\n",
      "            9.6658e-03,  0.0000e+00],\n",
      "          [-7.8577e-03, -3.6505e-03,  2.4284e+00,  ...,  9.9994e-01,\n",
      "            1.0964e-02,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 4.1794e-03, -6.4106e-03,  7.5113e-01,  ...,  6.6941e-01,\n",
      "           -7.4290e-01,  0.0000e+00],\n",
      "          [ 4.3078e-03, -6.6123e-03,  7.1435e-01,  ...,  6.4938e-01,\n",
      "           -7.6047e-01,  0.0000e+00],\n",
      "          [ 4.4287e-03, -6.8194e-03,  6.7546e-01,  ...,  6.3067e-01,\n",
      "           -7.7605e-01,  0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.0988e-01, -2.2837e+00, -1.2602e-01,  ...,  2.8528e-02,\n",
      "            9.9959e-01,  0.0000e+00],\n",
      "          [ 5.0988e-01, -2.2837e+00, -1.2602e-01,  ...,  2.8528e-02,\n",
      "            9.9959e-01,  0.0000e+00],\n",
      "          [ 5.0988e-01, -2.2837e+00, -1.2602e-01,  ...,  2.8528e-02,\n",
      "            9.9959e-01,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 5.0988e-01, -2.2837e+00, -1.2602e-01,  ...,  2.8528e-02,\n",
      "            9.9959e-01,  0.0000e+00],\n",
      "          [ 5.0988e-01, -2.2837e+00, -1.2602e-01,  ...,  2.8528e-02,\n",
      "            9.9959e-01,  0.0000e+00],\n",
      "          [ 5.0988e-01, -2.2837e+00, -1.2602e-01,  ...,  2.8528e-02,\n",
      "            9.9959e-01,  0.0000e+00]],\n",
      "\n",
      "         [[ 5.0988e-01, -2.2837e+00, -1.2602e-01,  ...,  2.8528e-02,\n",
      "            9.9959e-01,  0.0000e+00],\n",
      "          [ 1.4520e-02,  2.5835e-02, -1.2602e-01,  ...,  9.9983e-01,\n",
      "            1.8419e-02,  6.0000e+00],\n",
      "          [ 1.4477e-02,  2.5843e-02, -1.2602e-01,  ...,  9.9983e-01,\n",
      "            1.8423e-02,  6.0000e+00],\n",
      "          ...,\n",
      "          [ 1.4319e-02,  2.5846e-02, -1.2602e-01,  ...,  9.9983e-01,\n",
      "            1.8550e-02,  6.0000e+00],\n",
      "          [ 1.4284e-02,  2.5848e-02, -1.2602e-01,  ...,  9.9983e-01,\n",
      "            1.8581e-02,  6.0000e+00],\n",
      "          [ 1.4258e-02,  2.5851e-02, -1.2602e-01,  ...,  9.9983e-01,\n",
      "            1.8602e-02,  6.0000e+00]],\n",
      "\n",
      "         [[ 5.0988e-01, -2.2837e+00, -1.2602e-01,  ...,  2.8528e-02,\n",
      "            9.9959e-01,  0.0000e+00],\n",
      "          [ 5.0988e-01, -2.2837e+00, -1.2602e-01,  ...,  2.8528e-02,\n",
      "            9.9959e-01,  0.0000e+00],\n",
      "          [ 5.0988e-01, -2.2837e+00, -1.2602e-01,  ...,  2.8528e-02,\n",
      "            9.9959e-01,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 5.0988e-01, -2.2837e+00, -1.2602e-01,  ...,  2.8528e-02,\n",
      "            9.9959e-01,  0.0000e+00],\n",
      "          [ 5.0988e-01, -2.2837e+00, -1.2602e-01,  ...,  2.8528e-02,\n",
      "            9.9959e-01,  0.0000e+00],\n",
      "          [ 5.0988e-01, -2.2837e+00, -1.2602e-01,  ...,  2.8528e-02,\n",
      "            9.9959e-01,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[-2.7392e-02, -8.0272e-05, -1.2602e-01,  ...,  1.0000e+00,\n",
      "            1.6036e-03,  0.0000e+00],\n",
      "          [-2.7130e-02, -7.9107e-05, -1.2602e-01,  ...,  1.0000e+00,\n",
      "            1.5006e-03,  0.0000e+00],\n",
      "          [-2.6797e-02, -7.7777e-05,  3.0649e+00,  ...,  1.0000e+00,\n",
      "            1.4043e-03,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 1.3520e-04, -1.3598e-04,  3.1319e+00,  ...,  1.0000e+00,\n",
      "           -3.9586e-04,  0.0000e+00],\n",
      "          [ 7.4319e-04, -1.3551e-04,  3.2346e+00,  ...,  1.0000e+00,\n",
      "           -1.7931e-04,  0.0000e+00],\n",
      "          [ 1.3501e-03, -1.3493e-04,  3.1452e+00,  ...,  1.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[-6.3433e-02, -8.7304e-04,  4.7990e+00,  ...,  9.9998e-01,\n",
      "           -5.6544e-03,  0.0000e+00],\n",
      "          [-6.3057e-02, -9.0346e-04,  4.7975e+00,  ...,  9.9997e-01,\n",
      "           -8.1131e-03,  0.0000e+00],\n",
      "          [-6.2578e-02, -9.3632e-04,  4.7933e+00,  ...,  9.9995e-01,\n",
      "           -9.7809e-03,  0.0000e+00],\n",
      "          ...,\n",
      "          [-2.3433e-02, -1.3403e-03,  4.7679e+00,  ...,  9.9996e-01,\n",
      "            9.4461e-03,  0.0000e+00],\n",
      "          [-2.2613e-02, -1.3961e-03,  4.7766e+00,  ...,  9.9994e-01,\n",
      "            1.0934e-02,  0.0000e+00],\n",
      "          [-2.1784e-02, -1.4247e-03,  4.7805e+00,  ...,  9.9997e-01,\n",
      "            8.0246e-03,  0.0000e+00]],\n",
      "\n",
      "         [[ 2.9604e-03, -1.7781e-03,  1.2418e+00,  ...,  9.9999e-01,\n",
      "            4.7158e-03,  0.0000e+00],\n",
      "          [ 3.0783e-03, -1.7771e-03,  1.2418e+00,  ...,  9.9999e-01,\n",
      "            4.5606e-03,  0.0000e+00],\n",
      "          [ 3.2328e-03, -1.7745e-03,  1.2682e+00,  ...,  9.9999e-01,\n",
      "            4.5137e-03,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 1.9266e-02, -1.8321e-03,  2.2204e+00,  ...,  9.9989e-01,\n",
      "            1.4979e-02,  0.0000e+00],\n",
      "          [ 1.9705e-02, -1.8465e-03,  2.2355e+00,  ...,  9.9994e-01,\n",
      "            1.1310e-02,  0.0000e+00],\n",
      "          [ 2.0142e-02, -1.8604e-03,  2.2561e+00,  ...,  9.9996e-01,\n",
      "            8.6877e-03,  0.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.3705e+00,  1.3932e+00, -1.2602e-01,  ..., -9.9991e-01,\n",
      "           -1.3566e-02,  0.0000e+00],\n",
      "          [ 2.3705e+00,  1.3932e+00, -1.2602e-01,  ..., -9.9991e-01,\n",
      "           -1.3566e-02,  0.0000e+00],\n",
      "          [ 2.3705e+00,  1.3932e+00, -1.2602e-01,  ..., -9.9991e-01,\n",
      "           -1.3566e-02,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 2.3705e+00,  1.3932e+00, -1.2602e-01,  ..., -9.9991e-01,\n",
      "           -1.3566e-02,  0.0000e+00],\n",
      "          [ 2.3705e+00,  1.3932e+00, -1.2602e-01,  ..., -9.9991e-01,\n",
      "           -1.3566e-02,  0.0000e+00],\n",
      "          [ 2.3705e+00,  1.3932e+00, -1.2602e-01,  ..., -9.9991e-01,\n",
      "           -1.3566e-02,  0.0000e+00]],\n",
      "\n",
      "         [[ 2.3705e+00,  1.3932e+00, -1.2602e-01,  ..., -9.9991e-01,\n",
      "           -1.3566e-02,  0.0000e+00],\n",
      "          [ 2.3705e+00,  1.3932e+00, -1.2602e-01,  ..., -9.9991e-01,\n",
      "           -1.3566e-02,  0.0000e+00],\n",
      "          [ 2.3705e+00,  1.3932e+00, -1.2602e-01,  ..., -9.9991e-01,\n",
      "           -1.3566e-02,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 2.3705e+00,  1.3932e+00, -1.2602e-01,  ..., -9.9991e-01,\n",
      "           -1.3566e-02,  0.0000e+00],\n",
      "          [ 2.3705e+00,  1.3932e+00, -1.2602e-01,  ..., -9.9991e-01,\n",
      "           -1.3566e-02,  0.0000e+00],\n",
      "          [ 2.3705e+00,  1.3932e+00, -1.2602e-01,  ..., -9.9991e-01,\n",
      "           -1.3566e-02,  0.0000e+00]],\n",
      "\n",
      "         [[ 2.3705e+00,  1.3932e+00, -1.2602e-01,  ..., -9.9991e-01,\n",
      "           -1.3566e-02,  0.0000e+00],\n",
      "          [ 2.3705e+00,  1.3932e+00, -1.2602e-01,  ..., -9.9991e-01,\n",
      "           -1.3566e-02,  0.0000e+00],\n",
      "          [ 2.3705e+00,  1.3932e+00, -1.2602e-01,  ..., -9.9991e-01,\n",
      "           -1.3566e-02,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 2.3705e+00,  1.3932e+00, -1.2602e-01,  ..., -9.9991e-01,\n",
      "           -1.3566e-02,  0.0000e+00],\n",
      "          [ 2.3705e+00,  1.3932e+00, -1.2602e-01,  ..., -9.9991e-01,\n",
      "           -1.3566e-02,  0.0000e+00],\n",
      "          [ 2.3705e+00,  1.3932e+00, -1.2602e-01,  ..., -9.9991e-01,\n",
      "           -1.3566e-02,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3501e-03, -1.3498e-04, -1.2602e-01,  ...,  1.0000e+00,\n",
      "            2.8339e-04,  0.0000e+00],\n",
      "          [ 1.3501e-03, -1.3498e-04, -1.2602e-01,  ...,  1.0000e+00,\n",
      "            2.7634e-04,  0.0000e+00],\n",
      "          [ 1.3501e-03, -1.3498e-04, -1.2603e-01,  ...,  1.0000e+00,\n",
      "            2.6831e-04,  0.0000e+00],\n",
      "          ...,\n",
      "          [ 1.3501e-03, -1.3493e-04, -1.2601e-01,  ...,  1.0000e+00,\n",
      "            9.5477e-06,  0.0000e+00],\n",
      "          [ 1.3501e-03, -1.3493e-04, -1.2601e-01,  ...,  1.0000e+00,\n",
      "            3.6924e-06,  0.0000e+00],\n",
      "          [ 1.3501e-03, -1.3493e-04, -1.2602e-01,  ...,  1.0000e+00,\n",
      "            0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[ 1.7134e-02,  8.9283e-03, -1.2602e-01,  ...,  1.0000e+00,\n",
      "            4.6832e-04,  8.0000e+00],\n",
      "          [ 1.7156e-02,  8.9656e-03, -1.2602e-01,  ...,  1.0000e+00,\n",
      "            4.7635e-04,  8.0000e+00],\n",
      "          [ 1.7190e-02,  9.0168e-03, -1.2602e-01,  ...,  1.0000e+00,\n",
      "            4.8625e-04,  8.0000e+00],\n",
      "          ...,\n",
      "          [ 1.7206e-02,  9.0645e-03, -1.2832e-01,  ...,  1.0000e+00,\n",
      "            1.4780e-03,  8.0000e+00],\n",
      "          [ 1.7213e-02,  9.0725e-03, -1.2914e-01,  ...,  1.0000e+00,\n",
      "            1.5041e-03,  8.0000e+00],\n",
      "          [ 1.7227e-02,  9.0892e-03, -1.2918e-01,  ...,  1.0000e+00,\n",
      "            1.5339e-03,  8.0000e+00]],\n",
      "\n",
      "         [[ 9.7102e-03, -1.6176e-02, -1.2588e-01,  ...,  1.0000e+00,\n",
      "            1.2209e-03,  6.0000e+00],\n",
      "          [ 9.7180e-03, -1.6180e-02, -1.2588e-01,  ...,  1.0000e+00,\n",
      "            1.2289e-03,  6.0000e+00],\n",
      "          [ 9.7279e-03, -1.6186e-02, -1.2582e-01,  ...,  1.0000e+00,\n",
      "            1.2388e-03,  6.0000e+00],\n",
      "          ...,\n",
      "          [ 9.8330e-03, -1.6518e-02, -1.2605e-01,  ...,  1.0000e+00,\n",
      "            2.2290e-03,  6.0000e+00],\n",
      "          [ 9.8333e-03, -1.6518e-02, -1.2604e-01,  ...,  1.0000e+00,\n",
      "            2.2551e-03,  6.0000e+00],\n",
      "          [ 9.8341e-03, -1.6519e-02, -1.2604e-01,  ...,  1.0000e+00,\n",
      "            2.2849e-03,  6.0000e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.5324e-01, -6.9027e-01, -1.2602e-01,  ...,  9.9944e-01,\n",
      "            3.3426e-02,  0.0000e+00],\n",
      "          [-2.5324e-01, -6.9027e-01, -1.2602e-01,  ...,  9.9944e-01,\n",
      "            3.3426e-02,  0.0000e+00],\n",
      "          [-2.5324e-01, -6.9027e-01, -1.2602e-01,  ...,  9.9944e-01,\n",
      "            3.3426e-02,  0.0000e+00],\n",
      "          ...,\n",
      "          [-2.5324e-01, -6.9027e-01, -1.2602e-01,  ...,  9.9944e-01,\n",
      "            3.3426e-02,  0.0000e+00],\n",
      "          [-2.5324e-01, -6.9027e-01, -1.2602e-01,  ...,  9.9944e-01,\n",
      "            3.3426e-02,  0.0000e+00],\n",
      "          [-2.5324e-01, -6.9027e-01, -1.2602e-01,  ...,  9.9944e-01,\n",
      "            3.3426e-02,  0.0000e+00]],\n",
      "\n",
      "         [[-2.5324e-01, -6.9027e-01, -1.2602e-01,  ...,  9.9944e-01,\n",
      "            3.3426e-02,  0.0000e+00],\n",
      "          [-2.5324e-01, -6.9027e-01, -1.2602e-01,  ...,  9.9944e-01,\n",
      "            3.3426e-02,  0.0000e+00],\n",
      "          [-2.5324e-01, -6.9027e-01, -1.2602e-01,  ...,  9.9944e-01,\n",
      "            3.3426e-02,  0.0000e+00],\n",
      "          ...,\n",
      "          [-2.5324e-01, -6.9027e-01, -1.2602e-01,  ...,  9.9944e-01,\n",
      "            3.3426e-02,  0.0000e+00],\n",
      "          [-2.5324e-01, -6.9027e-01, -1.2602e-01,  ...,  9.9944e-01,\n",
      "            3.3426e-02,  0.0000e+00],\n",
      "          [-2.5324e-01, -6.9027e-01, -1.2602e-01,  ...,  9.9944e-01,\n",
      "            3.3426e-02,  0.0000e+00]],\n",
      "\n",
      "         [[-2.5324e-01, -6.9027e-01, -1.2602e-01,  ...,  9.9944e-01,\n",
      "            3.3426e-02,  0.0000e+00],\n",
      "          [-2.5324e-01, -6.9027e-01, -1.2602e-01,  ...,  9.9944e-01,\n",
      "            3.3426e-02,  0.0000e+00],\n",
      "          [-2.5324e-01, -6.9027e-01, -1.2602e-01,  ...,  9.9944e-01,\n",
      "            3.3426e-02,  0.0000e+00],\n",
      "          ...,\n",
      "          [-2.5324e-01, -6.9027e-01, -1.2602e-01,  ...,  9.9944e-01,\n",
      "            3.3426e-02,  0.0000e+00],\n",
      "          [-2.5324e-01, -6.9027e-01, -1.2602e-01,  ...,  9.9944e-01,\n",
      "            3.3426e-02,  0.0000e+00],\n",
      "          [-2.5324e-01, -6.9027e-01, -1.2602e-01,  ...,  9.9944e-01,\n",
      "            3.3426e-02,  0.0000e+00]]]])\n"
     ]
    }
   ],
   "source": [
    "b = next(iter(train_loader))\n",
    "\n",
    "print(\"First sample:\", b[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "621844a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training from epoch 1\n",
      "Epoch 1/1000 | Train Loss: 0.000842 | Val Loss: 0.000570\n",
      "Epoch 2/1000 | Train Loss: 0.000284 | Val Loss: 0.000513\n",
      "Epoch 3/1000 | Train Loss: 0.000182 | Val Loss: 0.000488\n",
      "Epoch 4/1000 | Train Loss: 0.000131 | Val Loss: 0.000501\n",
      "Epoch 5/1000 | Train Loss: 0.000095 | Val Loss: 0.000493\n",
      "Epoch 6/1000 | Train Loss: 0.000071 | Val Loss: 0.000477\n",
      "✅ Best model saved at epoch 6 (val loss: 0.000477)\n",
      "Epoch 7/1000 | Train Loss: 0.000055 | Val Loss: 0.000473\n",
      "✅ Best model saved at epoch 7 (val loss: 0.000473)\n",
      "Epoch 8/1000 | Train Loss: 0.000045 | Val Loss: 0.000470\n",
      "✅ Best model saved at epoch 8 (val loss: 0.000470)\n",
      "Epoch 9/1000 | Train Loss: 0.000036 | Val Loss: 0.000480\n",
      "Epoch 10/1000 | Train Loss: 0.000029 | Val Loss: 0.000480\n",
      "🧪 Checkpoint saved at checkpoints/ckpt_epoch_0010.pt\n",
      "Epoch 11/1000 | Train Loss: 0.000024 | Val Loss: 0.000472\n",
      "Epoch 12/1000 | Train Loss: 0.000019 | Val Loss: 0.000479\n",
      "Epoch 13/1000 | Train Loss: 0.000015 | Val Loss: 0.000487\n",
      "Epoch 14/1000 | Train Loss: 0.000012 | Val Loss: 0.000480\n",
      "Epoch 15/1000 | Train Loss: 0.000010 | Val Loss: 0.000477\n",
      "Epoch 16/1000 | Train Loss: 0.000009 | Val Loss: 0.000472\n",
      "Epoch 17/1000 | Train Loss: 0.000007 | Val Loss: 0.000480\n",
      "Epoch 18/1000 | Train Loss: 0.000007 | Val Loss: 0.000498\n",
      "Epoch 19/1000 | Train Loss: 0.000006 | Val Loss: 0.000483\n",
      "Epoch 20/1000 | Train Loss: 0.000005 | Val Loss: 0.000479\n",
      "🧪 Checkpoint saved at checkpoints/ckpt_epoch_0020.pt\n",
      "Epoch 21/1000 | Train Loss: 0.000005 | Val Loss: 0.000507\n",
      "Epoch 22/1000 | Train Loss: 0.000004 | Val Loss: 0.000477\n",
      "Epoch 23/1000 | Train Loss: 0.000004 | Val Loss: 0.000501\n",
      "Epoch 24/1000 | Train Loss: 0.000004 | Val Loss: 0.000509\n",
      "Epoch 25/1000 | Train Loss: 0.000004 | Val Loss: 0.000494\n",
      "Epoch 26/1000 | Train Loss: 0.000003 | Val Loss: 0.000491\n",
      "Epoch 27/1000 | Train Loss: 0.000003 | Val Loss: 0.000486\n",
      "Epoch 28/1000 | Train Loss: 0.000003 | Val Loss: 0.000471\n",
      "Epoch 29/1000 | Train Loss: 0.000003 | Val Loss: 0.000479\n",
      "Epoch 30/1000 | Train Loss: 0.000003 | Val Loss: 0.000477\n",
      "🧪 Checkpoint saved at checkpoints/ckpt_epoch_0030.pt\n",
      "Epoch 31/1000 | Train Loss: 0.000003 | Val Loss: 0.000475\n",
      "Epoch 32/1000 | Train Loss: 0.000003 | Val Loss: 0.000478\n",
      "Epoch 33/1000 | Train Loss: 0.000002 | Val Loss: 0.000490\n",
      "Epoch 34/1000 | Train Loss: 0.000002 | Val Loss: 0.000472\n",
      "Epoch 35/1000 | Train Loss: 0.000002 | Val Loss: 0.000480\n",
      "Epoch 36/1000 | Train Loss: 0.000002 | Val Loss: 0.000478\n",
      "Epoch 37/1000 | Train Loss: 0.000002 | Val Loss: 0.000484\n",
      "Epoch 38/1000 | Train Loss: 0.000002 | Val Loss: 0.000496\n",
      "Epoch 39/1000 | Train Loss: 0.000002 | Val Loss: 0.000459\n",
      "✅ Best model saved at epoch 39 (val loss: 0.000459)\n",
      "Epoch 40/1000 | Train Loss: 0.000002 | Val Loss: 0.000501\n",
      "🧪 Checkpoint saved at checkpoints/ckpt_epoch_0040.pt\n",
      "Epoch 41/1000 | Train Loss: 0.000002 | Val Loss: 0.000481\n",
      "Epoch 42/1000 | Train Loss: 0.000002 | Val Loss: 0.000465\n",
      "Epoch 43/1000 | Train Loss: 0.000002 | Val Loss: 0.000485\n",
      "Epoch 44/1000 | Train Loss: 0.000002 | Val Loss: 0.000492\n",
      "Epoch 45/1000 | Train Loss: 0.000002 | Val Loss: 0.000522\n",
      "Epoch 46/1000 | Train Loss: 0.000002 | Val Loss: 0.000494\n",
      "Epoch 47/1000 | Train Loss: 0.000002 | Val Loss: 0.000474\n",
      "Epoch 48/1000 | Train Loss: 0.000002 | Val Loss: 0.000508\n",
      "Epoch 49/1000 | Train Loss: 0.000002 | Val Loss: 0.000489\n",
      "Epoch 50/1000 | Train Loss: 0.000002 | Val Loss: 0.000500\n",
      "🧪 Checkpoint saved at checkpoints/ckpt_epoch_0050.pt\n",
      "Epoch 51/1000 | Train Loss: 0.000002 | Val Loss: 0.000486\n",
      "Epoch 52/1000 | Train Loss: 0.000002 | Val Loss: 0.000486\n",
      "Epoch 53/1000 | Train Loss: 0.000002 | Val Loss: 0.000490\n",
      "Epoch 54/1000 | Train Loss: 0.000002 | Val Loss: 0.000514\n",
      "Epoch 55/1000 | Train Loss: 0.000002 | Val Loss: 0.000480\n",
      "Epoch 56/1000 | Train Loss: 0.000002 | Val Loss: 0.000493\n",
      "Epoch 57/1000 | Train Loss: 0.000002 | Val Loss: 0.000487\n",
      "Epoch 58/1000 | Train Loss: 0.000002 | Val Loss: 0.000495\n",
      "Epoch 59/1000 | Train Loss: 0.000002 | Val Loss: 0.000508\n",
      "Epoch 60/1000 | Train Loss: 0.000002 | Val Loss: 0.000501\n",
      "🧪 Checkpoint saved at checkpoints/ckpt_epoch_0060.pt\n",
      "Epoch 61/1000 | Train Loss: 0.000002 | Val Loss: 0.000477\n",
      "Epoch 62/1000 | Train Loss: 0.000001 | Val Loss: 0.000493\n",
      "Epoch 63/1000 | Train Loss: 0.000002 | Val Loss: 0.000499\n",
      "Epoch 64/1000 | Train Loss: 0.000001 | Val Loss: 0.000488\n",
      "Epoch 65/1000 | Train Loss: 0.000001 | Val Loss: 0.000494\n",
      "Epoch 66/1000 | Train Loss: 0.000001 | Val Loss: 0.000475\n",
      "Epoch 67/1000 | Train Loss: 0.000001 | Val Loss: 0.000477\n",
      "Epoch 68/1000 | Train Loss: 0.000001 | Val Loss: 0.000516\n",
      "Epoch 69/1000 | Train Loss: 0.000001 | Val Loss: 0.000475\n",
      "Epoch 70/1000 | Train Loss: 0.000001 | Val Loss: 0.000483\n",
      "🧪 Checkpoint saved at checkpoints/ckpt_epoch_0070.pt\n",
      "Epoch 71/1000 | Train Loss: 0.000001 | Val Loss: 0.000499\n",
      "Epoch 72/1000 | Train Loss: 0.000001 | Val Loss: 0.000509\n",
      "Epoch 73/1000 | Train Loss: 0.000001 | Val Loss: 0.000514\n",
      "Epoch 74/1000 | Train Loss: 0.000001 | Val Loss: 0.000503\n",
      "Epoch 75/1000 | Train Loss: 0.000001 | Val Loss: 0.000487\n",
      "Epoch 76/1000 | Train Loss: 0.000001 | Val Loss: 0.000496\n",
      "Epoch 77/1000 | Train Loss: 0.000001 | Val Loss: 0.000487\n",
      "Epoch 78/1000 | Train Loss: 0.000001 | Val Loss: 0.000481\n",
      "Epoch 79/1000 | Train Loss: 0.000001 | Val Loss: 0.000459\n",
      "Epoch 80/1000 | Train Loss: 0.000001 | Val Loss: 0.000493\n",
      "🧪 Checkpoint saved at checkpoints/ckpt_epoch_0080.pt\n",
      "Epoch 81/1000 | Train Loss: 0.000001 | Val Loss: 0.000490\n",
      "Epoch 82/1000 | Train Loss: 0.000001 | Val Loss: 0.000479\n",
      "Epoch 83/1000 | Train Loss: 0.000001 | Val Loss: 0.000483\n",
      "Epoch 84/1000 | Train Loss: 0.000001 | Val Loss: 0.000477\n",
      "Epoch 85/1000 | Train Loss: 0.000001 | Val Loss: 0.000468\n",
      "Epoch 86/1000 | Train Loss: 0.000001 | Val Loss: 0.000496\n",
      "Epoch 87/1000 | Train Loss: 0.000001 | Val Loss: 0.000497\n",
      "Epoch 88/1000 | Train Loss: 0.000001 | Val Loss: 0.000488\n",
      "Epoch 89/1000 | Train Loss: 0.000001 | Val Loss: 0.000496\n",
      "Epoch 90/1000 | Train Loss: 0.000001 | Val Loss: 0.000468\n",
      "🧪 Checkpoint saved at checkpoints/ckpt_epoch_0090.pt\n",
      "Epoch 91/1000 | Train Loss: 0.000001 | Val Loss: 0.000484\n",
      "Epoch 92/1000 | Train Loss: 0.000001 | Val Loss: 0.000516\n",
      "Epoch 93/1000 | Train Loss: 0.000001 | Val Loss: 0.000480\n",
      "Epoch 94/1000 | Train Loss: 0.000001 | Val Loss: 0.000477\n",
      "Epoch 95/1000 | Train Loss: 0.000001 | Val Loss: 0.000489\n",
      "Epoch 96/1000 | Train Loss: 0.000001 | Val Loss: 0.000499\n",
      "Epoch 97/1000 | Train Loss: 0.000001 | Val Loss: 0.000483\n",
      "Epoch 98/1000 | Train Loss: 0.000001 | Val Loss: 0.000487\n",
      "Epoch 99/1000 | Train Loss: 0.000001 | Val Loss: 0.000471\n",
      "Epoch 100/1000 | Train Loss: 0.000001 | Val Loss: 0.000498\n",
      "🧪 Checkpoint saved at checkpoints/ckpt_epoch_0100.pt\n",
      "Epoch 101/1000 | Train Loss: 0.000001 | Val Loss: 0.000486\n",
      "Epoch 102/1000 | Train Loss: 0.000001 | Val Loss: 0.000503\n",
      "Epoch 103/1000 | Train Loss: 0.000001 | Val Loss: 0.000477\n",
      "Epoch 104/1000 | Train Loss: 0.000001 | Val Loss: 0.000497\n",
      "Epoch 105/1000 | Train Loss: 0.000001 | Val Loss: 0.000490\n",
      "Epoch 106/1000 | Train Loss: 0.000001 | Val Loss: 0.000502\n",
      "Epoch 107/1000 | Train Loss: 0.000001 | Val Loss: 0.000504\n",
      "Epoch 108/1000 | Train Loss: 0.000001 | Val Loss: 0.000499\n",
      "Epoch 109/1000 | Train Loss: 0.000001 | Val Loss: 0.000480\n",
      "Epoch 110/1000 | Train Loss: 0.000001 | Val Loss: 0.000490\n",
      "🧪 Checkpoint saved at checkpoints/ckpt_epoch_0110.pt\n",
      "Epoch 111/1000 | Train Loss: 0.000001 | Val Loss: 0.000481\n",
      "Epoch 112/1000 | Train Loss: 0.000001 | Val Loss: 0.000484\n",
      "Epoch 113/1000 | Train Loss: 0.000001 | Val Loss: 0.000496\n",
      "Epoch 114/1000 | Train Loss: 0.000001 | Val Loss: 0.000498\n",
      "Epoch 115/1000 | Train Loss: 0.000001 | Val Loss: 0.000469\n",
      "Epoch 116/1000 | Train Loss: 0.000001 | Val Loss: 0.000482\n",
      "Epoch 117/1000 | Train Loss: 0.000001 | Val Loss: 0.000496\n",
      "Epoch 118/1000 | Train Loss: 0.000001 | Val Loss: 0.000472\n",
      "Epoch 119/1000 | Train Loss: 0.000001 | Val Loss: 0.000475\n",
      "Epoch 120/1000 | Train Loss: 0.000001 | Val Loss: 0.000475\n",
      "🧪 Checkpoint saved at checkpoints/ckpt_epoch_0120.pt\n",
      "Epoch 121/1000 | Train Loss: 0.000001 | Val Loss: 0.000494\n",
      "Epoch 122/1000 | Train Loss: 0.000001 | Val Loss: 0.000492\n",
      "Epoch 123/1000 | Train Loss: 0.000001 | Val Loss: 0.000486\n",
      "Epoch 124/1000 | Train Loss: 0.000001 | Val Loss: 0.000487\n",
      "Epoch 125/1000 | Train Loss: 0.000001 | Val Loss: 0.000493\n",
      "Epoch 126/1000 | Train Loss: 0.000001 | Val Loss: 0.000494\n",
      "Epoch 127/1000 | Train Loss: 0.000001 | Val Loss: 0.000486\n",
      "Epoch 128/1000 | Train Loss: 0.000001 | Val Loss: 0.000500\n",
      "Epoch 129/1000 | Train Loss: 0.000001 | Val Loss: 0.000482\n",
      "Epoch 130/1000 | Train Loss: 0.000001 | Val Loss: 0.000486\n",
      "🧪 Checkpoint saved at checkpoints/ckpt_epoch_0130.pt\n",
      "Epoch 131/1000 | Train Loss: 0.000001 | Val Loss: 0.000492\n",
      "Epoch 132/1000 | Train Loss: 0.000001 | Val Loss: 0.000475\n",
      "Epoch 133/1000 | Train Loss: 0.000001 | Val Loss: 0.000496\n",
      "Epoch 134/1000 | Train Loss: 0.000001 | Val Loss: 0.000477\n",
      "Epoch 135/1000 | Train Loss: 0.000001 | Val Loss: 0.000483\n",
      "Epoch 136/1000 | Train Loss: 0.000001 | Val Loss: 0.000482\n",
      "Epoch 137/1000 | Train Loss: 0.000001 | Val Loss: 0.000498\n",
      "Epoch 138/1000 | Train Loss: 0.000001 | Val Loss: 0.000491\n",
      "Epoch 139/1000 | Train Loss: 0.000001 | Val Loss: 0.000476\n",
      "Epoch 140/1000 | Train Loss: 0.000001 | Val Loss: 0.000476\n",
      "🧪 Checkpoint saved at checkpoints/ckpt_epoch_0140.pt\n",
      "Epoch 141/1000 | Train Loss: 0.000001 | Val Loss: 0.000482\n",
      "Epoch 142/1000 | Train Loss: 0.000001 | Val Loss: 0.000473\n",
      "Epoch 143/1000 | Train Loss: 0.000001 | Val Loss: 0.000485\n",
      "Epoch 144/1000 | Train Loss: 0.000001 | Val Loss: 0.000488\n",
      "Epoch 145/1000 | Train Loss: 0.000001 | Val Loss: 0.000493\n",
      "Epoch 146/1000 | Train Loss: 0.000001 | Val Loss: 0.000481\n",
      "Epoch 147/1000 | Train Loss: 0.000001 | Val Loss: 0.000486\n",
      "Epoch 148/1000 | Train Loss: 0.000001 | Val Loss: 0.000468\n",
      "Epoch 149/1000 | Train Loss: 0.000001 | Val Loss: 0.000492\n",
      "Epoch 150/1000 | Train Loss: 0.000001 | Val Loss: 0.000502\n",
      "🧪 Checkpoint saved at checkpoints/ckpt_epoch_0150.pt\n",
      "Epoch 151/1000 | Train Loss: 0.000001 | Val Loss: 0.000477\n",
      "Epoch 152/1000 | Train Loss: 0.000001 | Val Loss: 0.000494\n",
      "Epoch 153/1000 | Train Loss: 0.000001 | Val Loss: 0.000490\n",
      "Epoch 154/1000 | Train Loss: 0.000001 | Val Loss: 0.000496\n",
      "Epoch 155/1000 | Train Loss: 0.000001 | Val Loss: 0.000476\n",
      "Epoch 156/1000 | Train Loss: 0.000001 | Val Loss: 0.000494\n",
      "Epoch 157/1000 | Train Loss: 0.000001 | Val Loss: 0.000486\n",
      "Epoch 158/1000 | Train Loss: 0.000001 | Val Loss: 0.000489\n",
      "Epoch 159/1000 | Train Loss: 0.000001 | Val Loss: 0.000493\n",
      "Epoch 160/1000 | Train Loss: 0.000001 | Val Loss: 0.000492\n",
      "🧪 Checkpoint saved at checkpoints/ckpt_epoch_0160.pt\n",
      "Epoch 161/1000 | Train Loss: 0.000001 | Val Loss: 0.000490\n",
      "Epoch 162/1000 | Train Loss: 0.000001 | Val Loss: 0.000487\n",
      "Epoch 163/1000 | Train Loss: 0.000001 | Val Loss: 0.000478\n",
      "Epoch 164/1000 | Train Loss: 0.000001 | Val Loss: 0.000486\n",
      "Epoch 165/1000 | Train Loss: 0.000001 | Val Loss: 0.000479\n",
      "Epoch 166/1000 | Train Loss: 0.000001 | Val Loss: 0.000488\n",
      "Epoch 167/1000 | Train Loss: 0.000001 | Val Loss: 0.000494\n",
      "Epoch 168/1000 | Train Loss: 0.000001 | Val Loss: 0.000486\n",
      "Epoch 169/1000 | Train Loss: 0.000001 | Val Loss: 0.000474\n",
      "Epoch 170/1000 | Train Loss: 0.000001 | Val Loss: 0.000493\n",
      "🧪 Checkpoint saved at checkpoints/ckpt_epoch_0170.pt\n",
      "Epoch 171/1000 | Train Loss: 0.000001 | Val Loss: 0.000485\n",
      "Epoch 172/1000 | Train Loss: 0.000001 | Val Loss: 0.000482\n",
      "Epoch 173/1000 | Train Loss: 0.000001 | Val Loss: 0.000463\n",
      "Epoch 174/1000 | Train Loss: 0.000001 | Val Loss: 0.000473\n",
      "Epoch 175/1000 | Train Loss: 0.000001 | Val Loss: 0.000493\n",
      "Epoch 176/1000 | Train Loss: 0.000001 | Val Loss: 0.000490\n",
      "Epoch 177/1000 | Train Loss: 0.000001 | Val Loss: 0.000491\n",
      "Epoch 178/1000 | Train Loss: 0.000001 | Val Loss: 0.000484\n",
      "Epoch 179/1000 | Train Loss: 0.000001 | Val Loss: 0.000485\n",
      "Epoch 180/1000 | Train Loss: 0.000001 | Val Loss: 0.000488\n",
      "🧪 Checkpoint saved at checkpoints/ckpt_epoch_0180.pt\n",
      "Epoch 181/1000 | Train Loss: 0.000001 | Val Loss: 0.000487\n",
      "Epoch 182/1000 | Train Loss: 0.000001 | Val Loss: 0.000473\n",
      "Epoch 183/1000 | Train Loss: 0.000001 | Val Loss: 0.000496\n",
      "Epoch 184/1000 | Train Loss: 0.000001 | Val Loss: 0.000485\n",
      "Epoch 185/1000 | Train Loss: 0.000001 | Val Loss: 0.000490\n",
      "Epoch 186/1000 | Train Loss: 0.000001 | Val Loss: 0.000487\n",
      "Epoch 187/1000 | Train Loss: 0.000001 | Val Loss: 0.000486\n",
      "Epoch 188/1000 | Train Loss: 0.000001 | Val Loss: 0.000507\n",
      "Epoch 189/1000 | Train Loss: 0.000001 | Val Loss: 0.000486\n",
      "Epoch 190/1000 | Train Loss: 0.000001 | Val Loss: 0.000489\n",
      "🧪 Checkpoint saved at checkpoints/ckpt_epoch_0190.pt\n",
      "Epoch 191/1000 | Train Loss: 0.000001 | Val Loss: 0.000488\n",
      "Epoch 192/1000 | Train Loss: 0.000001 | Val Loss: 0.000490\n",
      "Epoch 193/1000 | Train Loss: 0.000001 | Val Loss: 0.000500\n",
      "Epoch 194/1000 | Train Loss: 0.000001 | Val Loss: 0.000482\n",
      "Epoch 195/1000 | Train Loss: 0.000001 | Val Loss: 0.000483\n",
      "Epoch 196/1000 | Train Loss: 0.000001 | Val Loss: 0.000493\n",
      "Epoch 197/1000 | Train Loss: 0.000001 | Val Loss: 0.000492\n",
      "Epoch 198/1000 | Train Loss: 0.000001 | Val Loss: 0.000484\n",
      "Epoch 199/1000 | Train Loss: 0.000001 | Val Loss: 0.000491\n",
      "Epoch 200/1000 | Train Loss: 0.000001 | Val Loss: 0.000480\n",
      "🧪 Checkpoint saved at checkpoints/ckpt_epoch_0200.pt\n",
      "Epoch 201/1000 | Train Loss: 0.000001 | Val Loss: 0.000491\n",
      "Epoch 202/1000 | Train Loss: 0.000001 | Val Loss: 0.000503\n",
      "Epoch 203/1000 | Train Loss: 0.000001 | Val Loss: 0.000486\n",
      "Epoch 204/1000 | Train Loss: 0.000001 | Val Loss: 0.000479\n",
      "Epoch 205/1000 | Train Loss: 0.000001 | Val Loss: 0.000480\n",
      "Epoch 206/1000 | Train Loss: 0.000001 | Val Loss: 0.000483\n",
      "Epoch 207/1000 | Train Loss: 0.000001 | Val Loss: 0.000480\n",
      "Epoch 208/1000 | Train Loss: 0.000001 | Val Loss: 0.000485\n",
      "Epoch 209/1000 | Train Loss: 0.000001 | Val Loss: 0.000482\n",
      "Epoch 210/1000 | Train Loss: 0.000001 | Val Loss: 0.000485\n",
      "🧪 Checkpoint saved at checkpoints/ckpt_epoch_0210.pt\n",
      "Epoch 211/1000 | Train Loss: 0.000001 | Val Loss: 0.000494\n",
      "Epoch 212/1000 | Train Loss: 0.000001 | Val Loss: 0.000488\n",
      "Epoch 213/1000 | Train Loss: 0.000001 | Val Loss: 0.000497\n",
      "Epoch 214/1000 | Train Loss: 0.000001 | Val Loss: 0.000486\n",
      "Epoch 215/1000 | Train Loss: 0.000001 | Val Loss: 0.000483\n",
      "Epoch 216/1000 | Train Loss: 0.000001 | Val Loss: 0.000492\n",
      "Epoch 217/1000 | Train Loss: 0.000001 | Val Loss: 0.000482\n",
      "Epoch 218/1000 | Train Loss: 0.000001 | Val Loss: 0.000487\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting training from epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart_epoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_epoch, epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# Train for one epoch\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# Evaluate on validation set\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m evaluate(model, val_loader, device)\n",
      "Cell \u001b[0;32mIn[30], line 10\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, dataloader, optimizer, device, clip_grad)\u001b[0m\n\u001b[1;32m      7\u001b[0m past, mask, future \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[1;32m      9\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 10\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpast\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(pred, future)\n\u001b[1;32m     13\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[29], line 116\u001b[0m, in \u001b[0;36mImprovedTrajectoryTransformer.forward\u001b[0;34m(self, past, agent_mask)\u001b[0m\n\u001b[1;32m    113\u001b[0m agent_features \u001b[38;5;241m=\u001b[39m temporal_output[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(B, N, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_model)  \u001b[38;5;66;03m# B, N, d_model\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# Make sure there's at least one valid agent per batch\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;241m~\u001b[39magent_mask)\u001b[38;5;241m.\u001b[39mall(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m    117\u001b[0m     fallback_mask \u001b[38;5;241m=\u001b[39m agent_mask\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m    118\u001b[0m     fallback_mask[:, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# At least use ego vehicle\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create model, optimizer, and scheduler\n",
    "model = ImprovedTrajectoryTransformer(feature_dim=7, dropout=.3).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay, betas=(0.9, 0.999))\n",
    "warm_up_epochs = 5\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs - warm_up_epochs, eta_min=1e-6)\n",
    "warm_up_scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda epoch: (epoch + 1) / warm_up_epochs if epoch < warm_up_epochs else 1)\n",
    "os.makedirs(checkpoints_dir, exist_ok=True)\n",
    "\n",
    "# Training setup\n",
    "start_epoch = 1\n",
    "best_val_loss = float('inf')\n",
    "no_improve_epochs = 0\n",
    "\n",
    "# Try to load checkpoint\n",
    "latest_ckpt = get_latest_checkpoint(checkpoints_dir)\n",
    "if latest_ckpt:\n",
    "    print(f\"Loading checkpoint: {latest_ckpt}\")\n",
    "    ckpt = torch.load(latest_ckpt, map_location=device)\n",
    "    model.load_state_dict(ckpt['model_state_dict'])\n",
    "    optimizer.load_state_dict(ckpt['optimizer_state_dict'])\n",
    "    start_epoch = ckpt['epoch'] + 1\n",
    "    best_val_loss = ckpt.get('val_loss', float('inf'))\n",
    "    print(f\"✅ Resumed from epoch {start_epoch - 1} with val_loss={best_val_loss:.6f}\")\n",
    "\n",
    "writer = SummaryWriter(log_dir=\"runs/exp1\")   # creates runs/exp1/*\n",
    "\n",
    "# Training loop\n",
    "print(f\"Starting training from epoch {start_epoch}\")\n",
    "for epoch in range(start_epoch, epochs + 1):\n",
    "    # Train for one epoch\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, device)\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    val_loss = evaluate(model, val_loader, device)\n",
    "    \n",
    "    # Update learning rate\n",
    "    if epoch <= warm_up_epochs:\n",
    "        warm_up_scheduler.step()\n",
    "    else:\n",
    "        scheduler.step()\n",
    "    \n",
    "    # Print progress\n",
    "    print(f\"Epoch {epoch}/{epochs} | Train Loss: {train_loss:.6f} | Val Loss: {val_loss:.6f}\")\n",
    "    writer.add_scalar(\"Loss/Train\", train_loss, epoch)\n",
    "    writer.add_scalar(\"Loss/Val\",   val_loss,   epoch)\n",
    "    \n",
    "    # Save best model\n",
    "    if val_loss <= best_val_loss and epoch > warm_up_epochs:\n",
    "        best_val_loss = val_loss\n",
    "        no_improve_epochs = 0\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': best_val_loss\n",
    "        }, checkpoint_path)\n",
    "        print(f\"✅ Best model saved at epoch {epoch} (val loss: {best_val_loss:.6f})\")\n",
    "    else:\n",
    "        no_improve_epochs += 1\n",
    "    \n",
    "    # Save periodic checkpoint\n",
    "    if epoch % 10 == 0:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_loss\n",
    "        }, f'{checkpoints_dir}/ckpt_epoch_{epoch:04d}.pt')\n",
    "        print(f\"🧪 Checkpoint saved at {checkpoints_dir}/ckpt_epoch_{epoch:04d}.pt\")\n",
    "    \n",
    "    # Early stopping\n",
    "    # if no_improve_epochs >= patience:\n",
    "    #     print(f\"Early stopping triggered after {epoch} epochs\")\n",
    "    #     break\n",
    "writer.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cc077203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading best model for prediction...\n",
      "Generating predictions...\n",
      "Predictions saved to predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# Load best model for prediction\n",
    "print(\"Loading best model for prediction...\")\n",
    "model.load_state_dict(torch.load(checkpoint_path, map_location=device)['model_state_dict'])\n",
    "\n",
    "# Generate predictions\n",
    "print(\"Generating predictions...\")\n",
    "preds = predict(model, test_loader, test_ds, device)\n",
    "\n",
    "# Flatten predictions to match submission format (2100*60, 2)\n",
    "preds_flat = preds.reshape(-1, 2)\n",
    "\n",
    "# Create ID column (required for submission)\n",
    "ids = np.arange(len(preds_flat))\n",
    "\n",
    "# Save predictions to CSV\n",
    "output = np.column_stack((ids, preds_flat))\n",
    "header = \"index,x,y\"\n",
    "np.savetxt(output_csv, output, delimiter=',', header=header, comments='', fmt=['%d', '%.6f', '%.6f'])\n",
    "print(f\"Predictions saved to {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8767159d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Past XY reconstruction max‐error: 2.842e-14\n",
      "Future invariance max‐error: 0.000e+00\n",
      "Future norm/denorm max‐error: 7.105e-15\n",
      "Batch shapes:\n",
      "  past: torch.Size([8, 50, 50, 7])\n",
      "  mask: torch.Size([8, 50])\n",
      "  centers: torch.Size([8, 2])\n",
      "  thetas: torch.Size([8])\n",
      "  pred_world: (8, 60, 2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# assume: TrajectoryDataset, invariance_transform, inverse_transform,\n",
    "#         align_future, collate_fn, etc. are already defined above\n",
    "\n",
    "ds = TrajectoryDataset(input_path='data/train.npz', is_test=False)\n",
    "\n",
    "# pick one scene\n",
    "idx = 0\n",
    "scene = ds.data[idx]\n",
    "\n",
    "# 1) PAST reconstruction test\n",
    "# — slice ALL features, not just :2\n",
    "raw_past_feats = scene[:, :ds.T_past, :].copy()           # (A, T_past, F>=4)\n",
    "aligned_feats, center, theta = invariance_transform(raw_past_feats) #one aligned scene\n",
    "\n",
    "# now inverse only the XY channels\n",
    "recon_xy = inverse_transform(aligned_feats[..., :2], center, theta)\n",
    "err_past = np.max(np.abs(recon_xy - raw_past_feats[..., :2]))\n",
    "print(f'Past XY reconstruction max‐error: {err_past:.3e}')\n",
    "\n",
    "if scene.shape[1] >= ds.T_past + ds.T_future:\n",
    "    raw_fut = scene[0, ds.T_past:ds.T_past+ds.T_future, :2].copy()\n",
    "\n",
    "    # 1) align → inverse (should reconstruct raw_fut up to numerical noise)\n",
    "    fut_aln   = align_future(raw_fut, center, theta)\n",
    "    recon_if  = inverse_transform(fut_aln, center, theta)\n",
    "    err_if    = np.max(np.abs(recon_if - raw_fut))\n",
    "    print(f'Future invariance max‐error: {err_if:.3e}')\n",
    "\n",
    "    # 2) normalization → denormalization (should also be tiny)\n",
    "    fut_norm  = (fut_aln - ds.pos_mean) / ds.pos_std\n",
    "    fut_den   = ds.denormalize_prediction(fut_norm)\n",
    "    err_scale = np.max(np.abs(fut_den - fut_aln))\n",
    "    print(f'Future norm/denorm max‐error: {err_scale:.3e}')\n",
    "\n",
    "# 3) BATCH shapes test\n",
    "ds_test = TrajectoryDataset(input_path='data/train.npz', is_test=True)\n",
    "loader  = DataLoader(ds_test, batch_size=8, collate_fn=collate_fn)\n",
    "past_b, mask_b, centers_b, thetas_b = next(iter(loader))\n",
    "print('Batch shapes:')\n",
    "print('  past:',     past_b.shape)       # (8, A, T_past, F)\n",
    "print('  mask:',     mask_b.shape)       # (8, A)\n",
    "print('  centers:',  centers_b.shape)    # (8, 2)\n",
    "print('  thetas:',   thetas_b.shape)     # (8,)\n",
    "\n",
    "# quick pipeline shape‐check\n",
    "pred_norm = np.random.randn(8, ds.T_future, 2)\n",
    "pred_aln  = ds.denormalize_prediction(pred_norm)\n",
    "pred_w    = inverse_transform(pred_aln, centers_b.numpy(), thetas_b.numpy())\n",
    "print('  pred_world:', pred_w.shape)    # (8, T_future, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7762b24",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
